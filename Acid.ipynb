{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Acid.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNVw9pmNAzkpXpfpVWGlpVB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alirezash97/BRATS2015/blob/master/Acid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-Z45GiMM57l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "\n",
        "def Acid32(last_chance, X, checker):\n",
        "\n",
        "  if checker == 0:\n",
        "    chance = random.uniform(0, 1)\n",
        "    checker = 1\n",
        "  else:\n",
        "    chance = last_chance\n",
        "    checker = 0\n",
        "\n",
        "  if chance > 0.8:\n",
        "    X = Dense(32, activation='relu')(X)\n",
        "  elif 0.8 > chance > 0.6:\n",
        "    X = Dense(32, activation='relu')(X)\n",
        "  elif 0.6 > chance > 0.4:\n",
        "    X = Dense(32, activation='relu')(X)\n",
        "  elif 0.4 > chance > 0.2:\n",
        "    X = Dense(32, activation='relu')(X)\n",
        "  elif 0.2 > chance :\n",
        "    X = Dense(32, activation='relu')(X)\n",
        "\n",
        "  return chance, X, checker\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ869EJ4W93L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "\n",
        "def Acid64(last_chance, X, checker):\n",
        "\n",
        "  if checker == 0:\n",
        "    chance = random.uniform(0, 1)\n",
        "    checker = 1\n",
        "  else:\n",
        "    chance = last_chance\n",
        "    checker = 0\n",
        "\n",
        "  if chance > 0.8:\n",
        "    X = Dense(64, activation='relu')(X)\n",
        "  elif 0.8 > chance > 0.6:\n",
        "    X = Dense(64, activation='relu')(X)\n",
        "  elif 0.6 > chance > 0.4:\n",
        "    X = Dense(64, activation='relu')(X)\n",
        "  elif 0.4 > chance > 0.2:\n",
        "    X = Dense(64, activation='relu')(X)\n",
        "  elif 0.2 > chance :\n",
        "    X = Dense(64, activation='relu')(X)\n",
        "\n",
        "  return chance, X, checker"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYmsGw2cXBuA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "\n",
        "def Acid128(last_chance, X, checker):\n",
        "\n",
        "  if checker == 0:\n",
        "    chance = random.uniform(0, 1)\n",
        "    checker = 1\n",
        "  else:\n",
        "    chance = last_chance\n",
        "    checker = 0\n",
        "\n",
        "  if chance > 0.8:\n",
        "    X = Dense(128, activation='relu')(X)\n",
        "  elif 0.8 > chance > 0.6:\n",
        "    X = Dense(128, activation='relu')(X)\n",
        "  elif 0.6 > chance > 0.4:\n",
        "    X = Dense(128, activation='relu')(X)\n",
        "  elif 0.4 > chance > 0.2:\n",
        "    X = Dense(128, activation='relu')(X)\n",
        "  elif 0.2 > chance :\n",
        "    X = Dense(128, activation='relu')(X)\n",
        "\n",
        "  return chance, X, checker"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNA_PT9UUApi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input\n",
        "from keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_SSPmaJVthl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# load the dataset\n",
        "dataset = loadtxt('/content/pima-indians-diabetes.data.csv', delimiter=',')\n",
        "# split into input (X) and output (y) variables\n",
        "train = dataset[:,0:8]\n",
        "target = dataset[:,8]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrcjJRgXV2Oo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "1221ce91-26ee-473e-eb0e-e24f8b89dfbd"
      },
      "source": [
        "# print(X.shape)\n",
        "# print(y.shape)"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(768, 8)\n",
            "(768,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V34ZUXnZ745",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train = X.reshape(768, 1, 8)\n",
        "# target = y.reshape(768, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMlbxdCxYq3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chance1, checker1 = (0.8, 0)\n",
        "chance2, checker2 = (0.8, 0)\n",
        "chance3, checker3 = (0.8, 0)\n",
        "chance4, checker4 = (0.8, 0)\n",
        "chance5, checker5 = (0.8, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qn7e8uZV5eB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "83de87f5-1a0b-453f-f564-d76053614c3c"
      },
      "source": [
        "X_input = Input(shape=(8,))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X = Dense(64, activation='relu')(X_input)\n",
        "\n",
        "\n",
        "chance1, X, checker1 = Acid32(chance1, X, checker1)\n",
        "chance2, X, checker2 = Acid64(chance2, X, checker2)\n",
        "chance3, X, checker3 = Acid128(chance3, X, checker3)\n",
        "chance4, X, checker4 = Acid64(chance4, X, checker4)\n",
        "chance5, X, checker5 = Acid32(chance5, X, checker5)\n",
        "\n",
        "out = Dense(1, activation='sigmoid')(X)\n",
        "\n",
        "model = Model(input=X_input, output=out)\n",
        "model.summary()"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_23 (InputLayer)        (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dense_137 (Dense)            (None, 64)                576       \n",
            "_________________________________________________________________\n",
            "dense_138 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_139 (Dense)            (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dense_140 (Dense)            (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_141 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_142 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_143 (Dense)            (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 23,457\n",
            "Trainable params: 23,457\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jk3q88ErZk76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.33, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ECXQeHoa93g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "5a04e16e-6cdf-4d8b-ce65-aa02441781d4"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(729, 8)\n",
            "(729,)\n",
            "(39, 8)\n",
            "(39,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5CPCf8YXZOM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8c0aa93c-d96b-4018-9957-e20dd23b576a"
      },
      "source": [
        "# compile the keras model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 514 samples, validate on 254 samples\n",
            "Epoch 1/100\n",
            "514/514 [==============================] - 0s 423us/step - loss: 0.9683 - accuracy: 0.6012 - val_loss: 0.7247 - val_accuracy: 0.5394\n",
            "Epoch 2/100\n",
            "514/514 [==============================] - 0s 76us/step - loss: 0.6112 - accuracy: 0.6848 - val_loss: 0.7083 - val_accuracy: 0.5748\n",
            "Epoch 3/100\n",
            "514/514 [==============================] - 0s 74us/step - loss: 0.6341 - accuracy: 0.6712 - val_loss: 0.6389 - val_accuracy: 0.6693\n",
            "Epoch 4/100\n",
            "514/514 [==============================] - 0s 72us/step - loss: 0.6195 - accuracy: 0.6868 - val_loss: 0.6289 - val_accuracy: 0.6969\n",
            "Epoch 5/100\n",
            "514/514 [==============================] - 0s 72us/step - loss: 0.5931 - accuracy: 0.6926 - val_loss: 0.6499 - val_accuracy: 0.6969\n",
            "Epoch 6/100\n",
            "514/514 [==============================] - 0s 71us/step - loss: 0.5987 - accuracy: 0.6965 - val_loss: 0.6711 - val_accuracy: 0.6654\n",
            "Epoch 7/100\n",
            "514/514 [==============================] - 0s 78us/step - loss: 0.6329 - accuracy: 0.6946 - val_loss: 0.6838 - val_accuracy: 0.6654\n",
            "Epoch 8/100\n",
            "514/514 [==============================] - 0s 78us/step - loss: 0.5916 - accuracy: 0.7043 - val_loss: 0.6419 - val_accuracy: 0.6772\n",
            "Epoch 9/100\n",
            "514/514 [==============================] - 0s 79us/step - loss: 0.5666 - accuracy: 0.7257 - val_loss: 0.6259 - val_accuracy: 0.6811\n",
            "Epoch 10/100\n",
            "514/514 [==============================] - 0s 72us/step - loss: 0.5545 - accuracy: 0.7315 - val_loss: 0.6336 - val_accuracy: 0.6969\n",
            "Epoch 11/100\n",
            "514/514 [==============================] - 0s 74us/step - loss: 0.5588 - accuracy: 0.7043 - val_loss: 0.6512 - val_accuracy: 0.6732\n",
            "Epoch 12/100\n",
            "514/514 [==============================] - 0s 78us/step - loss: 0.5455 - accuracy: 0.7276 - val_loss: 0.6487 - val_accuracy: 0.6142\n",
            "Epoch 13/100\n",
            "514/514 [==============================] - 0s 69us/step - loss: 0.6235 - accuracy: 0.6673 - val_loss: 0.6428 - val_accuracy: 0.6890\n",
            "Epoch 14/100\n",
            "514/514 [==============================] - 0s 75us/step - loss: 0.5688 - accuracy: 0.7198 - val_loss: 0.6983 - val_accuracy: 0.6220\n",
            "Epoch 15/100\n",
            "514/514 [==============================] - 0s 75us/step - loss: 0.5502 - accuracy: 0.7160 - val_loss: 0.6482 - val_accuracy: 0.6772\n",
            "Epoch 16/100\n",
            "514/514 [==============================] - 0s 84us/step - loss: 0.5710 - accuracy: 0.6926 - val_loss: 0.6635 - val_accuracy: 0.6260\n",
            "Epoch 17/100\n",
            "514/514 [==============================] - 0s 73us/step - loss: 0.5775 - accuracy: 0.6965 - val_loss: 0.6370 - val_accuracy: 0.7087\n",
            "Epoch 18/100\n",
            "514/514 [==============================] - 0s 73us/step - loss: 0.5462 - accuracy: 0.7198 - val_loss: 0.6263 - val_accuracy: 0.6890\n",
            "Epoch 19/100\n",
            "514/514 [==============================] - 0s 74us/step - loss: 0.5392 - accuracy: 0.7198 - val_loss: 0.6125 - val_accuracy: 0.7441\n",
            "Epoch 20/100\n",
            "514/514 [==============================] - 0s 78us/step - loss: 0.5276 - accuracy: 0.7257 - val_loss: 0.6153 - val_accuracy: 0.7402\n",
            "Epoch 21/100\n",
            "514/514 [==============================] - 0s 78us/step - loss: 0.5341 - accuracy: 0.7276 - val_loss: 0.6116 - val_accuracy: 0.6535\n",
            "Epoch 22/100\n",
            "514/514 [==============================] - 0s 76us/step - loss: 0.5536 - accuracy: 0.7121 - val_loss: 0.6493 - val_accuracy: 0.7087\n",
            "Epoch 23/100\n",
            "514/514 [==============================] - 0s 77us/step - loss: 0.5358 - accuracy: 0.7296 - val_loss: 0.6422 - val_accuracy: 0.7205\n",
            "Epoch 24/100\n",
            "514/514 [==============================] - 0s 73us/step - loss: 0.5361 - accuracy: 0.7296 - val_loss: 0.6564 - val_accuracy: 0.7165\n",
            "Epoch 25/100\n",
            "514/514 [==============================] - 0s 76us/step - loss: 0.5158 - accuracy: 0.7412 - val_loss: 0.6090 - val_accuracy: 0.7126\n",
            "Epoch 26/100\n",
            "514/514 [==============================] - 0s 72us/step - loss: 0.5040 - accuracy: 0.7451 - val_loss: 0.6087 - val_accuracy: 0.7126\n",
            "Epoch 27/100\n",
            "514/514 [==============================] - 0s 76us/step - loss: 0.4884 - accuracy: 0.7490 - val_loss: 0.6689 - val_accuracy: 0.7047\n",
            "Epoch 28/100\n",
            "514/514 [==============================] - 0s 81us/step - loss: 0.5798 - accuracy: 0.6984 - val_loss: 0.6652 - val_accuracy: 0.6457\n",
            "Epoch 29/100\n",
            "514/514 [==============================] - 0s 87us/step - loss: 0.5267 - accuracy: 0.7179 - val_loss: 0.6275 - val_accuracy: 0.6654\n",
            "Epoch 30/100\n",
            "514/514 [==============================] - 0s 72us/step - loss: 0.5242 - accuracy: 0.7432 - val_loss: 0.6890 - val_accuracy: 0.7205\n",
            "Epoch 31/100\n",
            "514/514 [==============================] - 0s 73us/step - loss: 0.5155 - accuracy: 0.7315 - val_loss: 0.6541 - val_accuracy: 0.7126\n",
            "Epoch 32/100\n",
            "514/514 [==============================] - 0s 73us/step - loss: 0.5301 - accuracy: 0.7374 - val_loss: 0.5830 - val_accuracy: 0.7126\n",
            "Epoch 33/100\n",
            "514/514 [==============================] - 0s 75us/step - loss: 0.4934 - accuracy: 0.7549 - val_loss: 0.6320 - val_accuracy: 0.6654\n",
            "Epoch 34/100\n",
            "514/514 [==============================] - 0s 77us/step - loss: 0.4785 - accuracy: 0.7549 - val_loss: 0.6417 - val_accuracy: 0.7244\n",
            "Epoch 35/100\n",
            "514/514 [==============================] - 0s 77us/step - loss: 0.5072 - accuracy: 0.7432 - val_loss: 0.6370 - val_accuracy: 0.6654\n",
            "Epoch 36/100\n",
            "514/514 [==============================] - 0s 78us/step - loss: 0.5019 - accuracy: 0.7393 - val_loss: 0.6115 - val_accuracy: 0.7008\n",
            "Epoch 37/100\n",
            "514/514 [==============================] - 0s 80us/step - loss: 0.4732 - accuracy: 0.7490 - val_loss: 0.6535 - val_accuracy: 0.6929\n",
            "Epoch 38/100\n",
            "514/514 [==============================] - 0s 75us/step - loss: 0.5000 - accuracy: 0.7471 - val_loss: 0.6092 - val_accuracy: 0.7047\n",
            "Epoch 39/100\n",
            "514/514 [==============================] - 0s 82us/step - loss: 0.4841 - accuracy: 0.7588 - val_loss: 0.6586 - val_accuracy: 0.6890\n",
            "Epoch 40/100\n",
            "514/514 [==============================] - 0s 73us/step - loss: 0.5556 - accuracy: 0.7004 - val_loss: 0.5906 - val_accuracy: 0.7008\n",
            "Epoch 41/100\n",
            "514/514 [==============================] - 0s 88us/step - loss: 0.4748 - accuracy: 0.7724 - val_loss: 0.6039 - val_accuracy: 0.7244\n",
            "Epoch 42/100\n",
            "514/514 [==============================] - 0s 74us/step - loss: 0.4523 - accuracy: 0.7743 - val_loss: 0.6455 - val_accuracy: 0.6575\n",
            "Epoch 43/100\n",
            "514/514 [==============================] - 0s 74us/step - loss: 0.4704 - accuracy: 0.7704 - val_loss: 0.5944 - val_accuracy: 0.7165\n",
            "Epoch 44/100\n",
            "514/514 [==============================] - 0s 77us/step - loss: 0.4951 - accuracy: 0.7549 - val_loss: 0.6140 - val_accuracy: 0.7087\n",
            "Epoch 45/100\n",
            "514/514 [==============================] - 0s 77us/step - loss: 0.4907 - accuracy: 0.7393 - val_loss: 0.6105 - val_accuracy: 0.7087\n",
            "Epoch 46/100\n",
            "514/514 [==============================] - 0s 73us/step - loss: 0.4821 - accuracy: 0.7724 - val_loss: 0.6136 - val_accuracy: 0.7244\n",
            "Epoch 47/100\n",
            "514/514 [==============================] - 0s 74us/step - loss: 0.4372 - accuracy: 0.7802 - val_loss: 0.6313 - val_accuracy: 0.7323\n",
            "Epoch 48/100\n",
            "514/514 [==============================] - 0s 76us/step - loss: 0.4302 - accuracy: 0.7763 - val_loss: 0.6095 - val_accuracy: 0.7362\n",
            "Epoch 49/100\n",
            "514/514 [==============================] - 0s 76us/step - loss: 0.4297 - accuracy: 0.7918 - val_loss: 0.6373 - val_accuracy: 0.7323\n",
            "Epoch 50/100\n",
            "514/514 [==============================] - 0s 75us/step - loss: 0.4303 - accuracy: 0.7899 - val_loss: 0.6559 - val_accuracy: 0.7402\n",
            "Epoch 51/100\n",
            "514/514 [==============================] - 0s 77us/step - loss: 0.4136 - accuracy: 0.8035 - val_loss: 0.7157 - val_accuracy: 0.6929\n",
            "Epoch 52/100\n",
            "514/514 [==============================] - 0s 75us/step - loss: 0.4829 - accuracy: 0.7607 - val_loss: 0.6655 - val_accuracy: 0.6575\n",
            "Epoch 53/100\n",
            "514/514 [==============================] - 0s 78us/step - loss: 0.4704 - accuracy: 0.7626 - val_loss: 0.6117 - val_accuracy: 0.7126\n",
            "Epoch 54/100\n",
            "514/514 [==============================] - 0s 72us/step - loss: 0.4477 - accuracy: 0.7685 - val_loss: 0.6393 - val_accuracy: 0.7323\n",
            "Epoch 55/100\n",
            "514/514 [==============================] - 0s 77us/step - loss: 0.4304 - accuracy: 0.7996 - val_loss: 0.6576 - val_accuracy: 0.7165\n",
            "Epoch 56/100\n",
            "514/514 [==============================] - 0s 72us/step - loss: 0.4165 - accuracy: 0.8016 - val_loss: 0.6366 - val_accuracy: 0.7402\n",
            "Epoch 57/100\n",
            "514/514 [==============================] - 0s 73us/step - loss: 0.4203 - accuracy: 0.7821 - val_loss: 0.6840 - val_accuracy: 0.7165\n",
            "Epoch 58/100\n",
            "514/514 [==============================] - 0s 77us/step - loss: 0.4307 - accuracy: 0.7763 - val_loss: 0.7219 - val_accuracy: 0.7165\n",
            "Epoch 59/100\n",
            "514/514 [==============================] - 0s 85us/step - loss: 0.4576 - accuracy: 0.7860 - val_loss: 0.6103 - val_accuracy: 0.7362\n",
            "Epoch 60/100\n",
            "514/514 [==============================] - 0s 79us/step - loss: 0.4158 - accuracy: 0.7879 - val_loss: 0.6318 - val_accuracy: 0.7283\n",
            "Epoch 61/100\n",
            "514/514 [==============================] - 0s 75us/step - loss: 0.4102 - accuracy: 0.8016 - val_loss: 0.7049 - val_accuracy: 0.7244\n",
            "Epoch 62/100\n",
            "514/514 [==============================] - 0s 73us/step - loss: 0.4151 - accuracy: 0.7996 - val_loss: 0.6639 - val_accuracy: 0.7244\n",
            "Epoch 63/100\n",
            "514/514 [==============================] - 0s 78us/step - loss: 0.3875 - accuracy: 0.8016 - val_loss: 0.6598 - val_accuracy: 0.7362\n",
            "Epoch 64/100\n",
            "514/514 [==============================] - 0s 75us/step - loss: 0.4237 - accuracy: 0.7938 - val_loss: 0.6819 - val_accuracy: 0.7047\n",
            "Epoch 65/100\n",
            "514/514 [==============================] - 0s 79us/step - loss: 0.5139 - accuracy: 0.7237 - val_loss: 0.6045 - val_accuracy: 0.7165\n",
            "Epoch 66/100\n",
            "514/514 [==============================] - 0s 85us/step - loss: 0.4760 - accuracy: 0.7412 - val_loss: 0.6163 - val_accuracy: 0.6732\n",
            "Epoch 67/100\n",
            "514/514 [==============================] - 0s 74us/step - loss: 0.4751 - accuracy: 0.7374 - val_loss: 0.6205 - val_accuracy: 0.6811\n",
            "Epoch 68/100\n",
            "514/514 [==============================] - 0s 75us/step - loss: 0.5391 - accuracy: 0.6887 - val_loss: 0.6689 - val_accuracy: 0.7126\n",
            "Epoch 69/100\n",
            "514/514 [==============================] - 0s 74us/step - loss: 0.4410 - accuracy: 0.7802 - val_loss: 0.6898 - val_accuracy: 0.6811\n",
            "Epoch 70/100\n",
            "514/514 [==============================] - 0s 80us/step - loss: 0.4409 - accuracy: 0.7763 - val_loss: 0.6564 - val_accuracy: 0.7402\n",
            "Epoch 71/100\n",
            "514/514 [==============================] - 0s 72us/step - loss: 0.4999 - accuracy: 0.7335 - val_loss: 0.6488 - val_accuracy: 0.7087\n",
            "Epoch 72/100\n",
            "514/514 [==============================] - 0s 76us/step - loss: 0.4733 - accuracy: 0.7879 - val_loss: 0.6747 - val_accuracy: 0.7362\n",
            "Epoch 73/100\n",
            "514/514 [==============================] - 0s 78us/step - loss: 0.4589 - accuracy: 0.7685 - val_loss: 0.6838 - val_accuracy: 0.7126\n",
            "Epoch 74/100\n",
            "514/514 [==============================] - 0s 72us/step - loss: 0.4456 - accuracy: 0.7840 - val_loss: 0.6760 - val_accuracy: 0.7323\n",
            "Epoch 75/100\n",
            "514/514 [==============================] - 0s 79us/step - loss: 0.4287 - accuracy: 0.7860 - val_loss: 0.6987 - val_accuracy: 0.7087\n",
            "Epoch 76/100\n",
            "514/514 [==============================] - 0s 77us/step - loss: 0.4036 - accuracy: 0.8113 - val_loss: 0.7826 - val_accuracy: 0.7205\n",
            "Epoch 77/100\n",
            "514/514 [==============================] - 0s 72us/step - loss: 0.4296 - accuracy: 0.7743 - val_loss: 0.6834 - val_accuracy: 0.7205\n",
            "Epoch 78/100\n",
            "514/514 [==============================] - 0s 80us/step - loss: 0.4131 - accuracy: 0.7860 - val_loss: 0.6924 - val_accuracy: 0.7283\n",
            "Epoch 79/100\n",
            "514/514 [==============================] - 0s 84us/step - loss: 0.4046 - accuracy: 0.8074 - val_loss: 0.7463 - val_accuracy: 0.7008\n",
            "Epoch 80/100\n",
            "514/514 [==============================] - 0s 78us/step - loss: 0.4786 - accuracy: 0.7763 - val_loss: 0.6598 - val_accuracy: 0.7283\n",
            "Epoch 81/100\n",
            "514/514 [==============================] - 0s 76us/step - loss: 0.4094 - accuracy: 0.8035 - val_loss: 0.6987 - val_accuracy: 0.7283\n",
            "Epoch 82/100\n",
            "514/514 [==============================] - 0s 73us/step - loss: 0.3902 - accuracy: 0.8054 - val_loss: 0.7399 - val_accuracy: 0.7126\n",
            "Epoch 83/100\n",
            "514/514 [==============================] - 0s 75us/step - loss: 0.4018 - accuracy: 0.7918 - val_loss: 0.7809 - val_accuracy: 0.7008\n",
            "Epoch 84/100\n",
            "514/514 [==============================] - 0s 71us/step - loss: 0.3930 - accuracy: 0.8113 - val_loss: 0.7617 - val_accuracy: 0.7047\n",
            "Epoch 85/100\n",
            "514/514 [==============================] - 0s 78us/step - loss: 0.4963 - accuracy: 0.7529 - val_loss: 0.6648 - val_accuracy: 0.7205\n",
            "Epoch 86/100\n",
            "514/514 [==============================] - 0s 74us/step - loss: 0.4597 - accuracy: 0.7704 - val_loss: 0.6710 - val_accuracy: 0.7126\n",
            "Epoch 87/100\n",
            "514/514 [==============================] - 0s 81us/step - loss: 0.4299 - accuracy: 0.8093 - val_loss: 0.6420 - val_accuracy: 0.7205\n",
            "Epoch 88/100\n",
            "514/514 [==============================] - 0s 73us/step - loss: 0.4601 - accuracy: 0.7763 - val_loss: 0.6988 - val_accuracy: 0.6772\n",
            "Epoch 89/100\n",
            "514/514 [==============================] - 0s 77us/step - loss: 0.4525 - accuracy: 0.7782 - val_loss: 0.6320 - val_accuracy: 0.7087\n",
            "Epoch 90/100\n",
            "514/514 [==============================] - 0s 73us/step - loss: 0.4373 - accuracy: 0.7743 - val_loss: 0.6412 - val_accuracy: 0.6969\n",
            "Epoch 91/100\n",
            "514/514 [==============================] - 0s 82us/step - loss: 0.4305 - accuracy: 0.7685 - val_loss: 0.6940 - val_accuracy: 0.7047\n",
            "Epoch 92/100\n",
            "514/514 [==============================] - 0s 78us/step - loss: 0.3892 - accuracy: 0.7938 - val_loss: 0.7290 - val_accuracy: 0.7008\n",
            "Epoch 93/100\n",
            "514/514 [==============================] - 0s 71us/step - loss: 0.3813 - accuracy: 0.8191 - val_loss: 0.7139 - val_accuracy: 0.6890\n",
            "Epoch 94/100\n",
            "514/514 [==============================] - 0s 77us/step - loss: 0.3914 - accuracy: 0.8093 - val_loss: 0.7022 - val_accuracy: 0.7087\n",
            "Epoch 95/100\n",
            "514/514 [==============================] - 0s 84us/step - loss: 0.3734 - accuracy: 0.8268 - val_loss: 0.7442 - val_accuracy: 0.6890\n",
            "Epoch 96/100\n",
            "514/514 [==============================] - 0s 71us/step - loss: 0.4056 - accuracy: 0.8191 - val_loss: 0.6617 - val_accuracy: 0.6850\n",
            "Epoch 97/100\n",
            "514/514 [==============================] - 0s 70us/step - loss: 0.3992 - accuracy: 0.8288 - val_loss: 0.6459 - val_accuracy: 0.7244\n",
            "Epoch 98/100\n",
            "514/514 [==============================] - 0s 72us/step - loss: 0.3693 - accuracy: 0.8210 - val_loss: 0.7740 - val_accuracy: 0.7244\n",
            "Epoch 99/100\n",
            "514/514 [==============================] - 0s 76us/step - loss: 0.3566 - accuracy: 0.8288 - val_loss: 0.7419 - val_accuracy: 0.7165\n",
            "Epoch 100/100\n",
            "514/514 [==============================] - 0s 76us/step - loss: 0.3356 - accuracy: 0.8444 - val_loss: 0.7583 - val_accuracy: 0.6929\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f1926bbe470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nm4KIXcOaRFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}