{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BraTS2020.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alirezash97/BraTS/blob/master/BraTS2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTyddrM8vWN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPuabDSM5Odq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget 'https://www.cbica.upenn.edu/MICCAI_BraTS2020_TrainingData'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwoe8nMu5ehU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !unzip /content/MICCAI_BraTS2020_TrainingData -d '/content/drive/My Drive/BRATS2020/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTatOtxqVt1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cp -r '/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/' /content/MICCAI_BraTS2020_TrainingData/"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHZM4grvNFhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "# print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "# try:\n",
        "#   tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "#   print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "# except ValueError:\n",
        "#   raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "# tf.config.experimental_connect_to_cluster(tpu)\n",
        "# tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaE9mk1bN0Mf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "\n",
        "# tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "# print ('TPU address is', tpu_address)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv49FBX66rwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from nibabel.testing import data_path\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import to_categorical\n",
        "import cv2\n",
        "import keras \n",
        "import random\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDDX_B0tDqMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "import glob, os\n",
        "images_path = glob.glob('/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/**/*.nii.gz', recursive=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynUxRs9LErvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_trainset_filenames = []\n",
        "y_trainset_filenames = []\n",
        "\n",
        "for item in images_path:\n",
        "  if 'seg' in item:\n",
        "    y_trainset_filenames.append(os.path.join(data_path, item))\n",
        "  else:\n",
        "    X_trainset_filenames.append(os.path.join(data_path, item))\n",
        "\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuYO0wBrFhXF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7aee6057-6949-48ad-dfb8-3201611440f5"
      },
      "source": [
        "print(len(X_trainset_filenames))\n",
        "print(len(y_trainset_filenames))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1476\n",
            "369\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixFKvntVve-h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "d9fc26f3-5633-42ef-9cf8-ba0e50ea582c"
      },
      "source": [
        "for i in range(8):\n",
        "  print(X_trainset_filenames[i:i+1])\n",
        "  print()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/BraTS20_Training_355/BraTS20_Training_355_t1.nii.gz']\n",
            "\n",
            "['/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/BraTS20_Training_355/BraTS20_Training_355_flair.nii.gz']\n",
            "\n",
            "['/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/BraTS20_Training_355/BraTS20_Training_355_t2.nii.gz']\n",
            "\n",
            "['/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/BraTS20_Training_355/BraTS20_Training_355_t1ce.nii.gz']\n",
            "\n",
            "['/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/BraTS20_Training_365/BraTS20_Training_365_t1ce.nii.gz']\n",
            "\n",
            "['/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/BraTS20_Training_365/BraTS20_Training_365_t1.nii.gz']\n",
            "\n",
            "['/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/BraTS20_Training_365/BraTS20_Training_365_t2.nii.gz']\n",
            "\n",
            "['/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/BraTS20_Training_365/BraTS20_Training_365_flair.nii.gz']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0LhMKIiwZ-5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "cfa370cf-99c2-4d76-c236-3022e5d98cce"
      },
      "source": [
        "for i in range(2):\n",
        "  print(y_trainset_filenames[i:i+1])\n",
        "  print()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/BraTS20_Training_355/BraTS20_Training_355_seg.nii.gz']\n",
            "\n",
            "['/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/BraTS20_Training_365/BraTS20_Training_365_seg.nii.gz']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_7guv-StMKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shuffle(sample_path, target_path):\n",
        "\n",
        "  a_list = list(range(0, len(target_path)))\n",
        "  random.shuffle(a_list)\n",
        "\n",
        "  new_sample_path = []\n",
        "  new_target_path = []\n",
        "  for i in a_list:\n",
        "    for j in range(4):\n",
        "      new_sample_path.append(sample_path[(i*4)+j])\n",
        "    new_target_path.append(target_path[i])\n",
        "\n",
        "  return new_sample_path, new_target_path\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNCpN1eZx6gi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_trainset_filenames, y_trainset_filenames = shuffle(X_trainset_filenames, y_trainset_filenames)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAI7o4noyItA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "c68e7a13-dd8b-4b41-a013-b55f6a67b0cf"
      },
      "source": [
        "for i in range(8):\n",
        "  print(X_trainset_filenames[i:i+1])\n",
        "  print()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/BraTS20_Training_137/BraTS20_Training_137_t1.nii.gz']\n",
            "\n",
            "['/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/BraTS20_Training_137/BraTS20_Training_137_t2.nii.gz']\n",
            "\n",
            "['/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/BraTS20_Training_137/BraTS20_Training_137_flair.nii.gz']\n",
            "\n",
            "['/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/BraTS20_Training_137/BraTS20_Training_137_t1ce.nii.gz']\n",
            "\n",
            "['/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/BraTS20_Training_063/BraTS20_Training_063_t2.nii.gz']\n",
            "\n",
            "['/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/BraTS20_Training_063/BraTS20_Training_063_flair.nii.gz']\n",
            "\n",
            "['/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/BraTS20_Training_063/BraTS20_Training_063_t1.nii.gz']\n",
            "\n",
            "['/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/BraTS20_Training_063/BraTS20_Training_063_t1ce.nii.gz']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efn9BaqRyPBu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d9bdb36d-0c55-4dbb-e086-1450ab09fcba"
      },
      "source": [
        "for i in range(2):\n",
        "  print(y_trainset_filenames[i:i+1])\n",
        "  print()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/BraTS20_Training_137/BraTS20_Training_137_seg.nii.gz']\n",
            "\n",
            "['/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/BraTS20_Training_063/BraTS20_Training_063_seg.nii.gz']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Arvv_C0tyZUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sort_by_channel(sample_path):\n",
        "\n",
        "  n = int(len(sample_path) / 4)\n",
        "  new_path = []\n",
        "  for i in range(n):\n",
        "    temp = sample_path[(i*4): (i+1)*4]\n",
        "    new_temp = []\n",
        "\n",
        "    ###############\n",
        "    for path in temp:\n",
        "      if '_t1.' in path:\n",
        "        new_temp.append(path)\n",
        "      else:\n",
        "        pass\n",
        "    for path in temp:\n",
        "      if '_t1ce.' in path:\n",
        "        new_temp.append(path)\n",
        "      else:\n",
        "        pass\n",
        "    for path in temp:\n",
        "      if '_t2.' in path:\n",
        "        new_temp.append(path)\n",
        "      else:\n",
        "        pass\n",
        "    for path in temp:\n",
        "      if '_flair.' in path:\n",
        "        new_temp.append(path)\n",
        "      else:\n",
        "        pass\n",
        "\n",
        "    ################    \n",
        "    for path in new_temp:\n",
        "      new_path.append(path)\n",
        "\n",
        "\n",
        "  return new_path\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixS9ItJ91Wcm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_trainset_filenames = sort_by_channel(X_trainset_filenames)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQc8DZCo1hFg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "1084325a-5c59-435e-dace-ffdcede6b7ae"
      },
      "source": [
        "for i in range(88, 96):\n",
        "  print(X_trainset_filenames[i:i+1])\n",
        "  print()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/BraTS20_Training_271/BraTS20_Training_271_t1.nii.gz']\n",
            "\n",
            "['/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/BraTS20_Training_271/BraTS20_Training_271_t1ce.nii.gz']\n",
            "\n",
            "['/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/BraTS20_Training_271/BraTS20_Training_271_t2.nii.gz']\n",
            "\n",
            "['/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/BraTS20_Training_271/BraTS20_Training_271_flair.nii.gz']\n",
            "\n",
            "['/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/BraTS20_Training_343/BraTS20_Training_343_t1.nii.gz']\n",
            "\n",
            "['/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/BraTS20_Training_343/BraTS20_Training_343_t1ce.nii.gz']\n",
            "\n",
            "['/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/BraTS20_Training_343/BraTS20_Training_343_t2.nii.gz']\n",
            "\n",
            "['/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/BraTS20_Training_343/BraTS20_Training_343_flair.nii.gz']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egTmWkkT1jfD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7cb3c33d-48e7-468d-bbfe-9a3cf5404d5a"
      },
      "source": [
        "for i in range(22, 24):\n",
        "  print(y_trainset_filenames[i:i+1])\n",
        "  print()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/BraTS20_Training_271/BraTS20_Training_271_seg.nii.gz']\n",
            "\n",
            "['/content/drive/My Drive/BRATS2020/MICCAI_BraTS2020_TrainingData/BraTS20_Training_343/BraTS20_Training_343_seg.nii.gz']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t9_aSBBzbeK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_labeled_image(image, label, is_categorical=False):\n",
        "    if not is_categorical:\n",
        "\n",
        "\n",
        "\n",
        "        ############## voxel categories were 0, 1, 2, 4 \n",
        "\n",
        "        for i in range(240):\n",
        "          for j in range(240):\n",
        "            for k in range(155):\n",
        "              if label[i, j, k] == 4.0 :\n",
        "                label[i, j, k] = 3.0\n",
        "              else:\n",
        "                pass\n",
        "\n",
        "\n",
        "        ########## voxel categpries are 0, 1, 2, 3 for better categorization \n",
        "\n",
        "\n",
        "        label = to_categorical(label, num_classes=4).astype(np.uint8)\n",
        "\n",
        "    image = cv2.normalize(image[:, :, :, 0], None, alpha=0, beta=255,\n",
        "                          norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F).astype(\n",
        "        np.uint8)\n",
        "\n",
        "    labeled_image = np.zeros_like(label[:, :, :, 1:])\n",
        "\n",
        "    # remove tumor part from image\n",
        "    labeled_image[:, :, :, 0] = image * (label[:, :, :, 0])\n",
        "    labeled_image[:, :, :, 1] = image * (label[:, :, :, 0])\n",
        "    labeled_image[:, :, :, 2] = image * (label[:, :, :, 0])\n",
        "\n",
        "    # color labels\n",
        "    labeled_image += label[:, :, :, 1:] * 255\n",
        "    return labeled_image"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cuyrfw-mzj0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_image_grid(image, unlabeled_image):\n",
        "\n",
        "\n",
        "\n",
        "    ############################################################################\n",
        "    data_all = []\n",
        "\n",
        "    data_all.append(image)\n",
        "\n",
        "    fig, ax = plt.subplots(3, 6, figsize=[16, 9])\n",
        "\n",
        "    # coronal plane\n",
        "    coronal = np.transpose(data_all, [1, 3, 2, 4, 0])\n",
        "    coronal = np.rot90(coronal, 1)\n",
        "\n",
        "    # transversal plane\n",
        "    transversal = np.transpose(data_all, [2, 1, 3, 4, 0])\n",
        "    transversal = np.rot90(transversal, 2)\n",
        "\n",
        "    # sagittal plane\n",
        "    sagittal = np.transpose(data_all, [2, 3, 1, 4, 0])\n",
        "    sagittal = np.rot90(sagittal, 1)\n",
        "\n",
        "    n_coronal = []\n",
        "    for i in range(6):\n",
        "        n = np.random.randint(coronal.shape[2])\n",
        "        n_coronal.append(n)\n",
        "\n",
        "        ax[0][i].imshow(np.squeeze(coronal[:, :, n, :]))\n",
        "        ax[0][i].set_xticks([])\n",
        "        ax[0][i].set_yticks([])\n",
        "        if i == 0:\n",
        "            ax[0][i].set_ylabel('Coronal', fontsize=15)\n",
        "\n",
        "    n_transversal = []\n",
        "    for i in range(6):\n",
        "        n = np.random.randint(transversal.shape[2])\n",
        "        n_transversal.append(n)\n",
        "\n",
        "        ax[1][i].imshow(np.squeeze(transversal[:, :, n, :]))\n",
        "        ax[1][i].set_xticks([])\n",
        "        ax[1][i].set_yticks([])\n",
        "        if i == 0:\n",
        "            ax[1][i].set_ylabel('Transversal', fontsize=15)\n",
        "\n",
        "    n_sagittal = []    \n",
        "    for i in range(6):\n",
        "        n = np.random.randint(sagittal.shape[2])\n",
        "        n_sagittal.append(n)\n",
        "\n",
        "        ax[2][i].imshow(np.squeeze(sagittal[:, :, n, :]))\n",
        "        ax[2][i].set_yticks([])\n",
        "        if i == 0:\n",
        "            ax[2][i].set_ylabel('Sagittal', fontsize=15)\n",
        "\n",
        "    fig.suptitle('\\n\\n#########################\\n #### labeled MRI ####\\n ##############################', fontsize=16, color='white')\n",
        "    fig.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "    ############################################################################\n",
        "\n",
        "    data_all = []\n",
        "\n",
        "    data_all.append(unlabeled_image)\n",
        "\n",
        "    fig, ax = plt.subplots(3, 6, figsize=[16, 9])\n",
        "\n",
        "    # coronal plane\n",
        "    coronal = np.transpose(data_all, [1, 3, 2, 4, 0])\n",
        "    coronal = np.rot90(coronal, 1)\n",
        "\n",
        "    # transversal plane\n",
        "    transversal = np.transpose(data_all, [2, 1, 3, 4, 0])\n",
        "    transversal = np.rot90(transversal, 2)\n",
        "\n",
        "    # sagittal plane\n",
        "    sagittal = np.transpose(data_all, [2, 3, 1, 4, 0])\n",
        "    sagittal = np.rot90(sagittal, 1)\n",
        "\n",
        "    for i in range(6):\n",
        "        ax[0][i].imshow(np.squeeze(coronal[:, :, n_coronal[i], 1]), cmap='gray')\n",
        "        ax[0][i].set_xticks([])\n",
        "        ax[0][i].set_yticks([])\n",
        "        if i == 0:\n",
        "            ax[0][i].set_ylabel('Coronal', fontsize=15)\n",
        "\n",
        "    for i in range(6):\n",
        "        ax[1][i].imshow(np.squeeze(transversal[:, :, n_transversal[i], 1]), cmap='gray')\n",
        "        ax[1][i].set_xticks([])\n",
        "        ax[1][i].set_yticks([])\n",
        "        if i == 0:\n",
        "            ax[1][i].set_ylabel('Transversal', fontsize=15)\n",
        "\n",
        "    for i in range(6):\n",
        "        ax[2][i].imshow(np.squeeze(sagittal[:, :, n_sagittal[i], 1]), cmap='gray')\n",
        "        ax[2][i].set_yticks([])\n",
        "        if i == 0:\n",
        "            ax[2][i].set_ylabel('Sagittal', fontsize=15)\n",
        "\n",
        "    fig.suptitle('\\n\\n#########################\\n #### unlabeled MRI ####\\n ##############################', fontsize=16, color='white')\n",
        "    fig.subplots_adjust(wspace=0, hspace=0)\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Pn_zycf0I_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_case(image_nifty_file, label_nifty_file):\n",
        "    \n",
        "    # load the image and label file, get the image content and return a numpy array for each\n",
        "    image = np.zeros((240, 240, 155, 4))\n",
        "\n",
        "    img0 = np.array(nib.load(image_nifty_file[0]).get_fdata())\n",
        "    img1 = np.array(nib.load(image_nifty_file[1]).get_fdata())\n",
        "    img2 = np.array(nib.load(image_nifty_file[2]).get_fdata())\n",
        "    img3 = np.array(nib.load(image_nifty_file[3]).get_fdata())\n",
        "    \n",
        "    image[:, :, :, 0] = img0\n",
        "    image[:, :, :, 1] = img1\n",
        "    image[:, :, :, 2] = img2\n",
        "    image[:, :, :, 3] = img3\n",
        "      \n",
        "    label = np.array(nib.load(label_nifty_file).get_fdata())\n",
        "    \n",
        "    \n",
        "    return image, label"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK5NO5XwBqTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image_unlabeled , label = load_case(X_trainset_filenames[:4], y_trainset_filenames[0])\n",
        "# image = get_labeled_image(image_unlabeled, label)\n",
        "\n",
        "# plot_image_grid(image, image_unlabeled)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOjR9fbyEgyZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import imageio\n",
        "from IPython.display import Image\n",
        "\n",
        "def visualize_data_gif(data_):\n",
        "    images = []\n",
        "    for i in range(data_.shape[0]):\n",
        "        x = data_[min(i, data_.shape[0] - 1), :, :]\n",
        "        y = data_[:, min(i, data_.shape[1] - 1), :]\n",
        "        z = data_[:, :, min(i, data_.shape[2] - 1)]\n",
        "        img = np.concatenate((x, y, z), axis=1)\n",
        "        images.append(img)\n",
        "    imageio.mimsave(\"/tmp/gif.gif\", images, duration=0.01)\n",
        "    return Image(filename=\"/tmp/gif.gif\", format='png')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqO9n63e3fLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ## combine t1, t1c, t2 and flair for patient 337 = X_trainset_filenames[4:8]\n",
        "# ## label for patient 337 = y_trainset_filenames[1]\n",
        "\n",
        "# image, label = load_case(X_trainset_filenames[4:8], y_trainset_filenames[1])\n",
        "# visualize_data_gif(get_labeled_image(image, label))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBh63cHoEniZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_sub_volume(image, label, \n",
        "                   orig_x = 240, orig_y = 240, orig_z = 155, \n",
        "                   output_x = 120, output_y = 120, output_z = 16,\n",
        "                   num_classes = 4, max_tries = 1000, \n",
        "                   background_threshold=0.95):\n",
        "  \n",
        "\n",
        "    ############## voxel categories were 0, 1, 2, 4 \n",
        "\n",
        "    for i in range(240):\n",
        "      for j in range(240):\n",
        "        for k in range(155):\n",
        "          if label[i, j, k] == 4.0 :\n",
        "            label[i, j, k] = 3.0\n",
        "          else:\n",
        "            pass\n",
        "\n",
        "\n",
        "    ########## voxel categpries are 0, 1, 2, 3 for better categorization \n",
        "\n",
        "    \n",
        "    # Initialize features and labels with `None`\n",
        "\n",
        "    \n",
        "    tries = 0\n",
        "    \n",
        "    while tries < max_tries:\n",
        "        # randomly sample sub-volume by sampling the corner voxel\n",
        "        # hint: make sure to leave enough room for the output dimensions!\n",
        "        start_x = np.random.randint(0, (orig_x - output_x + 1))\n",
        "        start_y = np.random.randint(0, (orig_y - output_y + 1))\n",
        "        start_z = np.random.randint(0, (orig_z - output_z + 1))\n",
        "\n",
        "        # extract relevant area of label\n",
        "        y = label[start_x: start_x + output_x,\n",
        "                  start_y: start_y + output_y,\n",
        "                  start_z: start_z + output_z]\n",
        "        \n",
        "        # One-hot encode the categories.\n",
        "        # This adds a 4th dimension, 'num_classes'\n",
        "        # (output_x, output_y, output_z, num_classes)\n",
        "        y = keras.utils.to_categorical(y, num_classes=num_classes)\n",
        "\n",
        "        # compute the background ratio\n",
        "        bgrd_ratio = np.sum(y[:, :, :, 0]) / (output_x * output_y * output_z)\n",
        "\n",
        "        # increment tries counter\n",
        "        tries += 1\n",
        "\n",
        "        # if background ratio is below the desired threshold,\n",
        "        # use that sub-volume.\n",
        "        # otherwise continue the loop and try another random sub-volume\n",
        "        if bgrd_ratio < background_threshold:\n",
        "\n",
        "            # make copy of the sub-volume\n",
        "            X = np.copy(image[start_x: start_x + output_x,\n",
        "                              start_y: start_y + output_y,\n",
        "                              start_z: start_z + output_z, :])\n",
        "            \n",
        "\n",
        "            random1 = np.random.uniform(0, 1)\n",
        "            random2 = np.random.uniform(0, 1)\n",
        "\n",
        "\n",
        "            # change dimension of X\n",
        "            # from (x_dim, y_dim, z_dim, num_channels)\n",
        "            # to (num_channels, x_dim, y_dim, z_dim)\n",
        "\n",
        "            \n",
        "            X = np.moveaxis(X, 3, 0)\n",
        "\n",
        "\n",
        "            if random1 > 0.5:\n",
        "\n",
        "              #########    data augmentation    ##############################\n",
        "\n",
        "              if random2 > 0.66:\n",
        "                #### 90 degree rotation #####\n",
        "                X = np.moveaxis(X, 1, 2)\n",
        "                #############################\n",
        "              \n",
        "              elif 0.33 < random2 <= 0.66:\n",
        "                #### 180 degree rotation ####\n",
        "                X = np.flip(X, (1, 2))\n",
        "                #############################\n",
        "              else :\n",
        "                #### 270 degree rotation #####\n",
        "                X = np.moveaxis(X, 1, 2)\n",
        "                X = np.flip(X, (1, 2))\n",
        "                ##############################\n",
        "\n",
        "              ###############################################################\n",
        "\n",
        "\n",
        "            else :\n",
        "              pass\n",
        "\n",
        "              \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # change dimension of y\n",
        "            # from (x_dim, y_dim, z_dim, num_classes)\n",
        "            # to (num_classes, x_dim, y_dim, z_dim)\n",
        "            y = np.moveaxis(y, 3, 0)\n",
        "\n",
        "\n",
        "            if random1 > 0.5:\n",
        "\n",
        "\n",
        "              #########    data augmentation    #############################\n",
        "\n",
        "              if random2 > 0.66:\n",
        "                #### 90 degree rotation #####\n",
        "                y = np.moveaxis(y, 1, 2)\n",
        "                #############################\n",
        "\n",
        "              elif 0.33 < random2 <= 0.66:\n",
        "                #### 180 degree rotation ####\n",
        "                y = np.flip(y, (1, 2))\n",
        "                #############################\n",
        "\n",
        "              else :\n",
        "                #### 270 degree rotation #####\n",
        "                y = np.moveaxis(y, 1, 2)\n",
        "                y = np.flip(y, (1, 2))\n",
        "                ##############################\n",
        "\n",
        "              ###############################################################\n",
        "\n",
        "            else :\n",
        "              pass\n",
        "              \n",
        "              \n",
        "\n",
        "\n",
        "\n",
        "            \n",
        "            # take a subset of y that excludes the background class\n",
        "            # in the 'num_classes' dimension\n",
        "            y = y[1:, :, :, :]\n",
        "    \n",
        "            return X, y"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZD7cwLGIJa_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize_patch(X, y):\n",
        "    fig, ax = plt.subplots(1, 2, figsize=[10, 5], squeeze=False)\n",
        "\n",
        "    ax[0][0].imshow(X[:, :, 0], cmap='Greys_r')\n",
        "    ax[0][0].set_yticks([])\n",
        "    ax[0][0].set_xticks([])\n",
        "    ax[0][1].imshow(y[:, :, 0], cmap='Greys_r')\n",
        "    ax[0][1].set_xticks([])\n",
        "    ax[0][1].set_yticks([])\n",
        "\n",
        "    fig.subplots_adjust(wspace=0, hspace=0)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pef6tKA5IodL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "dc2bafbd-6164-4f81-9989-e29ef34bf035"
      },
      "source": [
        "# image, label = load_case(X_trainset_filenames[4:8], y_trainset_filenames[1])\n",
        "# X, y = get_sub_volume(image, label)\n",
        "\n",
        "# #############\n",
        "# print(X.shape)\n",
        "# print(y.shape)\n",
        "# #############\n",
        "\n",
        "# # non-enhancing tumor is channel 1 in the class label\n",
        "# visualize_patch(X[1, :, :, :], y[1])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-0a300d744073>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_case\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trainset_filenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_trainset_filenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sub_volume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#############\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8C2KHLeJoPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# visualize_patch(X[1, :, :, :], y[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovECHH0JIb8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# visualize_patch(X[1, :, :, :], y[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp0eDzEhM4y3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def standardize(image):\n",
        "\n",
        "    one = 1\n",
        "    # initialize to array of zeros, with same shape as the image\n",
        "    standardized_image = np.zeros((image.shape[0], image.shape[1], image.shape[2], image.shape[3]))\n",
        "\n",
        "    # iterate over channels\n",
        "    for c in range(image.shape[0]):\n",
        "        # iterate over the `z` dimension\n",
        "        for z in range(image.shape[3]):\n",
        "            # get a slice of the image \n",
        "            # at channel c and z-th dimension `z`\n",
        "            image_slice = image[c,:,:,z]\n",
        "\n",
        "            # subtract the mean from image_slice\n",
        "            centered = image_slice - np.mean(image_slice)\n",
        "            \n",
        "            # divide by the standard deviation (only if it is different from zero)\n",
        "            if np.std(centered) != 0:\n",
        "                centered_scaled = centered / np.std(centered)\n",
        "            else:\n",
        "                ### error exception ### \n",
        "                centered_scaled = centered / one\n",
        "\n",
        "            # update  the slice of standardized image\n",
        "            # with the scaled centered and scaled image\n",
        "            standardized_image[c, :, :, z] = centered_scaled\n",
        "\n",
        "\n",
        "\n",
        "    return standardized_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AL4kU0_NWQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_norm = standardize(X)\n",
        "\n",
        "# visualize_patch(X_norm[1, :, :, :], y[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y_sPy4kPckY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dice_coefficient(y_true, y_pred, axis=(1, 2, 3), \n",
        "                     epsilon=0.00001):\n",
        "   \n",
        "\n",
        "    \n",
        "    \n",
        "    dice_numerator = 2 * K.sum(y_true * y_pred, axis=axis) + epsilon\n",
        "    dice_denominator = K.sum(y_true, axis=axis) + K.sum(y_pred, axis=axis) + epsilon\n",
        "    dice_coefficient = K.mean((dice_numerator)/(dice_denominator))\n",
        "    \n",
        "    \n",
        "\n",
        "    return dice_coefficient"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDy7pSCQPmP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def soft_dice_loss(y_true, y_pred, axis=(1, 2, 3), \n",
        "                   epsilon=0.00001):\n",
        "   \n",
        "\n",
        "    dice_numerator = 2. * K.sum(y_true * y_pred, axis=axis) + epsilon\n",
        "    dice_denominator = K.sum((y_true**2), axis=axis) + K.sum((y_pred**2), axis=axis) + epsilon\n",
        "    dice_loss = 1 - K.mean((dice_numerator)/(dice_denominator))\n",
        "\n",
        "   \n",
        "\n",
        "    return dice_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up-nHLflQRmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_convolution_block(input_layer, n_filters, batch_normalization=False,\n",
        "                             kernel=(3, 3, 3), activation=None,\n",
        "                             padding='same', strides=(1, 1, 1),\n",
        "                             instance_normalization=False):\n",
        "\n",
        "    layer = Conv3D(n_filters, kernel, padding=padding, strides=strides)(\n",
        "        input_layer)\n",
        "    if activation is None:\n",
        "        return Activation('relu')(layer)\n",
        "    else:\n",
        "        return activation()(layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzTkqeGpQULe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_up_convolution(n_filters, pool_size, kernel_size=(2, 2, 2),\n",
        "                       strides=(2, 2, 2),\n",
        "                       deconvolution=False):\n",
        "    if deconvolution:\n",
        "        return Deconvolution3D(filters=n_filters, kernel_size=kernel_size,\n",
        "                               strides=strides)\n",
        "    else:\n",
        "        return UpSampling3D(size=pool_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mb_sCqJQXir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unet_model_3d(loss_function, input_shape=(120, 120, 16, 4),\n",
        "                  pool_size=(2, 2, 2), n_labels=3,\n",
        "                  initial_learning_rate=0.00001,\n",
        "                  deconvolution=False, depth=4, n_base_filters=32,\n",
        "                  include_label_wise_dice_coefficients=False, metrics=[],\n",
        "                  batch_normalization=False, activation_name=\"sigmoid\", repeat=4):\n",
        "    \n",
        "\n",
        "    flower_outputs = list()\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "############################\n",
        "\n",
        "    for i in range(repeat):\n",
        "\n",
        "\n",
        "        current_layer = inputs\n",
        "        levels = []\n",
        "\n",
        "        # add levels with max pooling\n",
        "        for layer_depth in range(depth):\n",
        "            layer1 = create_convolution_block(input_layer=current_layer,\n",
        "                                              n_filters=n_base_filters * (\n",
        "                                                      2 ** layer_depth),\n",
        "                                              batch_normalization=batch_normalization)\n",
        "            layer2 = create_convolution_block(input_layer=layer1,\n",
        "                                              n_filters=n_base_filters * (\n",
        "                                                      2 ** layer_depth) * 2,\n",
        "                                              batch_normalization=batch_normalization)\n",
        "            if layer_depth < depth - 1:\n",
        "                current_layer = MaxPooling3D(pool_size=pool_size)(layer2)\n",
        "                levels.append([layer1, layer2, current_layer])\n",
        "            else:\n",
        "                current_layer = layer2\n",
        "                levels.append([layer1, layer2])\n",
        "\n",
        "        # add levels with up-convolution or up-sampling\n",
        "        for layer_depth in range(depth - 2, -1, -1):\n",
        "            up_convolution = get_up_convolution(pool_size=pool_size,\n",
        "                                                deconvolution=deconvolution,\n",
        "                                                n_filters=\n",
        "                                                current_layer._keras_shape[1])(\n",
        "                current_layer)\n",
        "            concat = concatenate([up_convolution, levels[layer_depth][1]], axis=-1)\n",
        "            current_layer = create_convolution_block(\n",
        "                n_filters=levels[layer_depth][1]._keras_shape[1],\n",
        "                input_layer=concat, batch_normalization=batch_normalization)\n",
        "            current_layer = create_convolution_block(\n",
        "                n_filters=levels[layer_depth][1]._keras_shape[1],\n",
        "                input_layer=current_layer,\n",
        "                batch_normalization=batch_normalization)\n",
        "            \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        flower_outputs.append(current_layer)\n",
        "        \n",
        "\n",
        "############################\n",
        "\n",
        "    ####### say number of repeats are 4 #############\n",
        "\n",
        "    \n",
        "    # final_layer0 = concatenate([flower_outputs[0], flower_outputs[1]])\n",
        "    # final_layer1 = concatenate([flower_outputs[2], flower_outputs[3]])\n",
        "    # final_layer_final = concatenate([final_layer0, final_layer1])\n",
        "\n",
        "###################################################\n",
        "\n",
        "    if repeat > 1:\n",
        "\n",
        "      final_layer = concatenate([flower_outputs[0], flower_outputs[1]])\n",
        "\n",
        "      for i in range(2, len(flower_outputs)):\n",
        "\n",
        "        final_layer = concatenate([final_layer, flower_outputs[i]])\n",
        "\n",
        "    else :\n",
        "      final_layer = flower_outputs[0]\n",
        "\n",
        "\n",
        "\n",
        "###########################\n",
        "\n",
        "\n",
        "    final_convolution = Conv3D(n_labels, (1, 1, 1))(final_layer)\n",
        "    act = Activation(activation_name)(final_convolution)\n",
        "    model = Model(inputs=inputs, outputs=act)\n",
        "\n",
        "    if not isinstance(metrics, list):\n",
        "        metrics = [metrics]\n",
        "\n",
        "    \n",
        "    model.compile(optimizer=Adam(lr=initial_learning_rate), loss=loss_function,\n",
        "                  metrics=metrics)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-8rf36tTIdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from keras.layers import Input, Conv3D, Activation, MaxPooling3D, UpSampling3D, concatenate\n",
        "# from keras import Model\n",
        "# from keras.optimizers import Adam\n",
        "# import keras.backend as K\n",
        "\n",
        "# with tpu_strategy.scope():\n",
        "#   model = unet_model_3d(loss_function=soft_dice_loss, metrics=[dice_coefficient])\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-GwsIKKNVwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################## server crashd andthis is model after two epoch ##############\n",
        "# load and evaluate a saved model\n",
        "from numpy import loadtxt\n",
        "from keras.models import load_model\n",
        "from keras.layers import Input, Conv3D, Activation, MaxPooling3D, UpSampling3D, concatenate\n",
        "from keras import Model\n",
        "from keras.optimizers import Adam\n",
        "import keras.backend as K\n",
        "\n",
        "# initial_learning_rate_for_loaded_model = 0.0001\n",
        "\n",
        "# load model\n",
        "model = load_model('/content/drive/My Drive/BRATS2020/tenth_FlowerModel_update.01-0.06.h5', custom_objects={'soft_dice_loss':soft_dice_loss, 'dice_coefficient':dice_coefficient})\n",
        "# learning rate decay beacuse this is thirth epoch that i'm loading \n",
        "# K.set_value(model.optimizer.learning_rate, initial_learning_rate_for_loaded_model)\n",
        "# summarize model.\n",
        "model.summary()\n",
        "# load dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZygp7RlHu5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.layers[-1].output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vZadDR8TMMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path_Xtrain = X_trainset_filenames[:1236]\n",
        "file_path_ytrain = y_trainset_filenames[:309]\n",
        "\n",
        "\n",
        "file_path_Xvalid = X_trainset_filenames[1236:]\n",
        "file_path_yvalid = y_trainset_filenames[309:]\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VAj0Rvof1Zx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator(X_path, y_path, batch_size=2):\n",
        "    \n",
        "\n",
        "\n",
        "    num_samples = len(X_path) / 4\n",
        "    while True: # Loop forever so the generator never terminates\n",
        "\n",
        " \n",
        "        # Get index to start each batch: [0, batch_size, 2*batch_size, ..., max multiple of batch_size &lt;= num_samples]\n",
        "        for offset in range(0, int(num_samples), batch_size):\n",
        "            \n",
        "            # Get the samples you'll use in this batch\n",
        "            batch_samples = X_path[ ((offset*4) * batch_size) : (((offset+1)*4) * batch_size) ]\n",
        "            batch_targets = y_path[ (offset*batch_size) : ((offset+1)*batch_size) ]\n",
        " \n",
        "            \n",
        "            \n",
        " \n",
        "            ### iterate 8 times on the same batch to generate 8 subvolumes of each image\n",
        "            for i in range(4): \n",
        "              \n",
        "              # Initialise X_train and y_train arrays for this batch\n",
        "              X_train = []\n",
        "              y_train = []\n",
        "\n",
        "              for i in range(len(batch_targets)):\n",
        "              \n",
        "                image, label = load_case(X_trainset_filenames[ (i*4) : ((i+1)*4) ], y_trainset_filenames[i])\n",
        "                X, y = get_sub_volume(image, label)\n",
        "                X_norm = standardize(X)\n",
        "                X_norm = np.moveaxis( X_norm, 0, 3)\n",
        "                y = np.moveaxis( y, 0, 3)\n",
        "                X_train.append(X_norm)\n",
        "                y_train.append(y)\n",
        "                \n",
        "                  \n",
        "  \n",
        "              # Make sure they're numpy arrays (as opposed to lists)\n",
        "\n",
        "              X_train = np.array(X_train)\n",
        "              y_train = np.array(y_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "              if X_train.ndim == 5:             \n",
        "                yield X_train, y_train\n",
        "              else:\n",
        "                pass\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBaAASMc4ctb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "x = np.random.uniform(0, 1)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBzLDhD3ojWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_generator = generator(file_path_Xtrain, file_path_ytrain, batch_size=2)\n",
        "validation_generator = generator(file_path_Xvalid, file_path_yvalid, batch_size=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8ynSMaEovMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "\n",
        "\n",
        "initial_learning_rate = 0.00001\n",
        "\n",
        "def scheduler(epoch):\n",
        "  \n",
        "  ## decrease learning rate every 3 epochs to 0.1(latest_value) ##\n",
        "  return float(initial_learning_rate * tf.math.exp(0.1 * (int(epoch/3))))\n",
        "  \n",
        "\n",
        "\n",
        "# callback\n",
        "my_callbacks = [\n",
        "        LearningRateScheduler(scheduler), \n",
        "        EarlyStopping(monitor='val_loss', patience=6),\n",
        "        ModelCheckpoint(filepath='/content/drive/My Drive/BRATS2020/eleventh_FlowerModel_update.{epoch:02d}-{val_loss:.2f}.h5', monitor='val_loss', save_best_only=False)\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "#### steps per epoch should be x/batch*8 because model generates 8 subvolumes per training sample\n",
        "# Fit model using generator\n",
        "history = model.fit(train_generator, steps_per_epoch=618, epochs=20, validation_data=validation_generator, validation_steps=120, callbacks=my_callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDky1zDYJ7Hi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}